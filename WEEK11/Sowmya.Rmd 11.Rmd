---
title: "Week 11 Assignment"
author: "Sowmya"
date: "2025-05-01"
output: html_document
---
```{r}
library(mlbench)
library(purrr)

data("PimaIndiansDiabetes2")
ds <- as.data.frame(na.omit(PimaIndiansDiabetes2))
## fit a logistic regression model to obtain a parametric equation
logmodel <- glm(diabetes ~ .,
                data = ds,
                family = "binomial")
summary(logmodel)

cfs <- coefficients(logmodel) ## extract the coefficients
prednames <- variable.names(ds)[-9] ## fetch the names of predictors in a vector
prednames

sz <- 100000000 ## to be used in sampling
##sample(ds$pregnant, size = sz, replace = T)

dfdata <- map_dfc(prednames,
                  function(nm){ ## function to create a sample-with-replacement for each pred.
                    eval(parse(text = paste0("sample(ds$",nm,
                                             ", size = sz, replace = T)")))
                  }) ## map the sample-generator on to the vector of predictors
## and combine them into a dataframe

names(dfdata) <- prednames
dfdata

class(cfs[2:length(cfs)])

length(cfs)
length(prednames)
## Next, compute the logit values
pvec <- map((1:8),
            function(pnum){
              cfs[pnum+1] * eval(parse(text = paste0("dfdata$",
                                                     prednames[pnum])))
            }) %>% ## create beta[i] * x[i]
  reduce(`+`) + ## sum(beta[i] * x[i])
  cfs[1] ## add the intercept

## exponentiate the logit to obtain probability values of thee outcome variable
dfdata$outcome <- ifelse(1/(1 + exp(-(pvec))) > 0.5,
                         1, 0)
```


```{r}
library(xgboost)
library(dplyr)
library(caret)

sample_sizes <- c(100, 1000, 10000, 100000, 1000000, 10000000)
results <- data.frame(
  SampleSize = integer(),
  Accuracy = numeric(),
  TimeTaken = numeric(),
  stringsAsFactors = FALSE
)

for (sz in sample_sizes) {
  cat("\nRunning sample size:", sz, "\n")
  set.seed(123)
  idx <- sample(1:nrow(dfdata), size = sz, replace = FALSE)
  data_sample <- dfdata[idx, ]
  trainIndex <- createDataPartition(data_sample$outcome, p = 0.8, list = FALSE)
  trainData <- data_sample[trainIndex, ]
  testData <- data_sample[-trainIndex, ]
  dtrain <- xgb.DMatrix(data = as.matrix(select(trainData, -outcome)),
                        label = trainData$outcome)
  dtest <- xgb.DMatrix(data = as.matrix(select(testData, -outcome)),
                       label = testData$outcome)
  params <- list(
    objective = "binary:logistic",
    eval_metric = "error",
    max_depth = 3,
    eta = 0.1
  )
  start_time <- Sys.time()
  
  model <- xgb.train(
    params = params,
    data = dtrain,
    nrounds = 50,
    verbose = 0
  )
  
  end_time <- Sys.time()
  preds <- predict(model, dtest)
  pred_labels <- ifelse(preds > 0.5, 1, 0)
  acc <- mean(pred_labels == testData$outcome)
  time_taken <- as.numeric(difftime(end_time, start_time, units = "secs"))
  results <- rbind(results, data.frame(SampleSize = sz,
                                       Accuracy = acc,
                                       TimeTaken = time_taken))
}

results
```

```{r}
library(caret)
library(xgboost)

# Function to evaluate XGBoost model with caret
evaluate_xgboost_caret <- function(data, outcome_col, sample_size) {
  
  # Ensure the sample size does not exceed the total number of rows in the data
  if(sample_size > nrow(data)) {
    indices <- sample(nrow(data), sample_size, replace = TRUE)  # Sample with replacement
  } else {
    indices <- sample(nrow(data), sample_size)  # Sample without replacement
  }
  
  # Select the sampled data
  sampled_data <- data[indices, ]
  
  set.seed(123)  # Set seed for reproducibility
  
  # Split data into training and test sets (80% training, 20% testing)
  train_indices <- createDataPartition(sampled_data[[outcome_col]], p = 0.8, list = FALSE)
  train_data <- sampled_data[train_indices, ]
  test_data <- sampled_data[-train_indices, ]
  
  # Convert outcome column to factor for classification task (Class0 = 0, Class1 = 1)
  train_data[[outcome_col]] <- factor(train_data[[outcome_col]], 
                                      levels = c(0, 1), 
                                      labels = c("Class0", "Class1"))
  test_data[[outcome_col]] <- factor(test_data[[outcome_col]], 
                                     levels = c(0, 1), 
                                     labels = c("Class0", "Class1"))

  # Set up cross-validation control for training
  ctrl <- trainControl(
    method = "cv",  # 5-fold cross-validation
    number = 5,
    verboseIter = FALSE,
    classProbs = TRUE,  # Allow probabilities for classes
    summaryFunction = twoClassSummary  # Use ROC for performance summary
  )

  # Grid for tuning XGBoost hyperparameters
  xgb_grid <- expand.grid(
    nrounds = 100,            # Number of boosting rounds
    eta = 0.1,                # Learning rate
    max_depth = 6,            # Maximum depth of trees
    gamma = 0,                # Regularization parameter
    colsample_bytree = 0.8,   # Proportion of columns to sample for each tree
    min_child_weight = 1,     # Minimum sum of instance weight (used in tree splitting)
    subsample = 0.8           # Proportion of data to sample for training
  )
  
  # Start the timer to measure training time
  start_time <- Sys.time()
  
  # Train the XGBoost model using caret's train function
  model <- train(
    x = train_data[, -which(names(train_data) == outcome_col)],  # Predictor variables
    y = train_data[[outcome_col]],  # Outcome variable
    method = "xgbTree",  # Using the XGBoost algorithm
    trControl = ctrl,  # Cross-validation control
    tuneGrid = xgb_grid,  # Hyperparameter grid
    metric = "ROC"  # Use ROC AUC for model evaluation
  )

  # End the timer after training
  end_time <- Sys.time()
  time_taken <- difftime(end_time, start_time, units = "secs")  # Calculate elapsed time
  
  # Make predictions on the test data
  predictions <- predict(model, test_data[, -which(names(test_data) == outcome_col)])
  
  # Calculate accuracy as the proportion of correct predictions
  accuracy <- sum(predictions == test_data[[outcome_col]]) / nrow(test_data)
  
  # Create confusion matrix and extract sensitivity and specificity
  conf_matrix <- confusionMatrix(predictions, test_data[[outcome_col]])

  # Return the results as a list
  return(list(
    method = "XGBoost via caret with 5-fold CV",  # Method name
    dataset_size = sample_size,  # Dataset sample size used
    training_size = nrow(train_data),  # Number of rows in the training set
    testing_size = nrow(test_data),  # Number of rows in the testing set
    accuracy = accuracy,  # Model accuracy
    sensitivity = conf_matrix$byClass["Sensitivity"],  # Sensitivity (True Positive Rate)
    specificity = conf_matrix$byClass["Specificity"],  # Specificity (True Negative Rate)
    time_seconds = as.numeric(time_taken)  # Time taken for training and evaluation
  ))
}

# Define different sample sizes to evaluate the model
sample_sizes <- c(100, 1000, 10000, 100000, 1000000, 10000000)

# Initialize an empty list to store results
results <- list()

# Loop through each sample size and evaluate the model
for(size in sample_sizes) {
  cat("Processing sample size:", size, "\n")
  
  # Evaluate the model for the current sample size
  result <- evaluate_xgboost_caret(dfdata, "outcome", size)
  
  # Store the result in the results list
  results[[as.character(size)]] <- result
  
  # Print immediate results for the current sample size
  cat("Sample size:", size, 
      "| Accuracy:", round(result$accuracy, 4), 
      "| Time:", round(result$time_seconds, 2), "seconds\n\n")
}

# Create a data frame to store the summary of results
result_table <- data.frame(
  Method = "XGBoost via caret with 5-fold CV",  # Method used for evaluation
  Dataset_Size = sample_sizes,  # Different sample sizes evaluated
  Testing_Performance = sapply(results, function(r) round(r$accuracy, 4)),  # Accuracy for each sample size
  Time_Seconds = sapply(results, function(r) round(r$time_seconds, 2))  # Time taken for each sample size
)

# Print the final summary of results
print(result_table)
```